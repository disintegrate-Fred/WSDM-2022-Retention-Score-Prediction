{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2022-01-06T02:46:33.584426Z",
     "iopub.status.busy": "2022-01-06T02:46:33.583625Z",
     "iopub.status.idle": "2022-01-06T02:46:33.601410Z",
     "shell.execute_reply": "2022-01-06T02:46:33.600428Z",
     "shell.execute_reply.started": "2022-01-06T02:46:33.584380Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import gc\n",
    "import json\n",
    "import copy\n",
    "import time\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "import scipy\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import dataset\n",
    "from torch.utils.data import dataloader\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data import Dataset\n",
    "from deepctr_torch.layers import DNN\n",
    "\n",
    "import torchvision\n",
    "from PIL import Image\n",
    "import torchvision.models as models\n",
    "import torchvision.transforms as transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_seed(seed):\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "\n",
    "\n",
    "random_seed(2021)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('data/onlinetrainbseqex3.csv')\n",
    "test = pd.read_csv('data/onlinetestbseqex3.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "del train['Unnamed: 0']\n",
    "del test['Unnamed: 0']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_pb = pd.read_csv('features/online_train_pb.csv').rename( columns = { 'date' : 'end_date' } )\n",
    "train = pd.merge(train, train_pb, how='left')\n",
    "\n",
    "test_pb = pd.read_csv('features/online_test_pb.csv').rename( columns = { 'date' : 'end_date' } )\n",
    "test = pd.merge(test, test_pb, how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_trait = pd.read_csv('features/user_trait_feature.csv')\n",
    "\n",
    "train = pd.merge(train, user_trait, how='left')\n",
    "test = pd.merge(test, user_trait, how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "launch_train = pd.read_csv('features/launch_online_train.csv').rename( columns = { 'date' : 'end_date' } )\n",
    "train = pd.merge(train, launch_train, how='left')\n",
    "\n",
    "launch_test = pd.read_csv('features/launch_online_test.csv').rename( columns = { 'date' : 'end_date' } )\n",
    "test = pd.merge(test, launch_test, how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['week'] = train['end_date'].apply(lambda x: (x-130)%7+1)\n",
    "test['week'] = test['end_date'].apply(lambda x: (x-130)%7+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = train.fillna(0)\n",
    "test = test.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "train[\"future\"] = train.future.apply(lambda x: json.loads(x))\n",
    "test[\"future\"] = test.future.apply(lambda x: json.loads(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['label'] = train['future'].apply(lambda x: sum(x))\n",
    "test['label'] = test['future'].apply(lambda x: sum(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['flag'] = train['label'].apply(lambda x: 1 if x>=6 else 0)\n",
    "test['flag'] = test['label'].apply(lambda x: 1 if x>=6 else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([transforms.Normalize(mean=[0.5,],std=[0.5,])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "feats = ['playtime_last0', 'video_count_last0', 'playtime_last1', 'video_count_last1', 'playtime_last2', 'video_count_last2',\n",
    "         'playtime_last3', 'video_count_last3', 'playtime_last4', 'video_count_last4', 'playtime_last5', 'video_count_last5',\n",
    "         'playtime_last6', 'video_count_last6', 'playtime_last7', 'video_count_last7', 'device_type', 'sex','age', 'education',\n",
    "         'occupation_status','device_ram_new','device_rom_new','diff_near','is_launch','launch_type_new','launchNum','NumLastWeek','preds_median_30',\n",
    "         'preds_mean_4','preds_mean_4_weighted','weighted_median','week']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "sparse_features = ['device_type','sex','age','education','occupation_status','week','is_launch','launch_type_new']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "dense_features = [x for x in feats if x not in sparse_features]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "33"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(feats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "voc_size = {}\n",
    "for i in sparse_features:\n",
    "    voc_size[i] = train[i].nunique()+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AQYDataset(Dataset):\n",
    "    def __init__(self, df, device):\n",
    "\n",
    "        self.launch_seq_list = df.list.apply( lambda x : json.loads(x.replace('nan' , '-1')) ).values\n",
    "        \n",
    "        self.sparse_feature_list = df[sparse_features].values\n",
    "        self.dense_feature_list = df[dense_features].values\n",
    "        \n",
    "        self.label_list = df['flag'].values\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "\n",
    "        \n",
    "        launch_seq = self.launch_seq_list[index]#[:128] \n",
    "        launch_seq = np.array(launch_seq).astype('float') \n",
    "        launch_seq.resize(8 , 8 , 3 )\n",
    "\n",
    "        label = self.label_list[index]\n",
    "        launch_seq = torch.tensor( launch_seq )\n",
    "        launch_seq = transform(launch_seq)\n",
    "        \n",
    "        sparse_feats = self.sparse_feature_list[index]\n",
    "        dense_feats = self.dense_feature_list[index]\n",
    "\n",
    "        return launch_seq, sparse_feats, dense_feats, label\n",
    "\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.launch_seq_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cal_score(pred, label):\n",
    "    pred = np.array(pred)\n",
    "    label = np.array(label)\n",
    "\n",
    "    diff = (pred - label) / 7\n",
    "    diff = np.abs(diff)\n",
    "\n",
    "    score = 100 * (1 - np.mean(diff))\n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN , self).__init__()\n",
    " \n",
    "        self.layer1 = nn.Sequential(  \n",
    "            nn.Conv2d(3, 16, kernel_size=3, stride=1, padding=2), \n",
    "            nn.BatchNorm2d(16), \n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2))\n",
    "\n",
    "        self.layer2 = nn.Sequential(\n",
    "            nn.Conv2d(16, 32, kernel_size=3, stride=1, padding=2),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2))\n",
    "        \n",
    "        emb_dict = {}\n",
    "        for feat in sparse_features:\n",
    "            emb_dict[feat] = nn.Embedding(voc_size[feat], 32)\n",
    "        self.embedding_layer =  nn.ModuleDict(emb_dict)\n",
    "        \n",
    "        self.fc = nn.Linear(288, 16)\n",
    "        \n",
    "        self.final = DNN(16+8*32+25, (64,32,1), activation='relu', \n",
    "                         l2_reg=0.03, dropout_rate=0.03, use_bn=True, device=device)\n",
    "\n",
    "   \n",
    "    def forward(self, x, sparse_feats, dense_feats):\n",
    "        out = self.layer1(x)\n",
    "        out = self.layer2(out)\n",
    "        out = out.reshape(out.size(0), -1)\n",
    "        out = self.fc(out)\n",
    "        \n",
    "        sparse_list = []\n",
    "        for i in range(len(sparse_features)):\n",
    "            sparse_list.append(self.embedding_layer[sparse_features[i]](sparse_feats[:,i]))\n",
    "        \n",
    "        sparse_emb = torch.cat(sparse_list, 1)\n",
    "        dnn_input = torch.cat([out, sparse_emb, dense_feats], 1)\n",
    "        result = self.final(dnn_input)\n",
    "\n",
    "        result = result.sigmoid()\n",
    "        \n",
    "        return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = CNN().to(device)\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.002)\n",
    "criterion = nn.BCELoss()\n",
    "best_val_score = float('-inf')\n",
    "last_improve = 0\n",
    "\n",
    "best_model = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = AQYDataset(train, device )\n",
    "test_dataset = AQYDataset(test, device )\n",
    "\n",
    "train_loader = DataLoader(train_dataset,\n",
    "                      batch_size=256*16,\n",
    "                      shuffle=True,\n",
    "                      num_workers=4)\n",
    "test_loader = DataLoader(test_dataset,\n",
    "                      batch_size=256*16,\n",
    "                      shuffle=False,\n",
    "                      num_workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "def cal_acc(label_list,pred_list):\n",
    "    pre_list = []\n",
    "    for i in pred_list:\n",
    "        if i>0.5:\n",
    "            pre_list.append(1)\n",
    "        else:\n",
    "            pre_list.append(0)\n",
    "            \n",
    "    return accuracy_score(label_list,pre_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f2e611dc5461411da05e26842cfb34a1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/777 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/shunyaowu/anaconda3/lib/python3.8/site-packages/torch/nn/functional.py:718: UserWarning: Named tensors and all their associated APIs are an experimental feature and subject to change. Please do not use them for anything important until they are released as stable. (Triggered internally at  /pytorch/c10/core/TensorImpl.h:1156.)\n",
      "  return torch.max_pool2d(input, kernel_size, stride, padding, dilation, ceil_mode)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0 Loss: 0.9092451664687292\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "694f71f1b41745be87750a755da8d9a4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/777 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 Loss: 0.925947394774452\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "addf28f51bff486a8b2cb8c4f681f356",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/777 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 2 Loss: 0.9263078337929508\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4f5d0dc4742447a7904cd89268517395",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/777 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 3 Loss: 0.9264864807061334\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a27cdd03e53f48958f8e84f9dca8f9f6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/777 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 4 Loss: 0.9267204830008655\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e6c591301fdc4232affa0e3c1ab8e620",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/777 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 5 Loss: 0.9267720641518549\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1a4b4666714247c181b2bd977b5c3cf9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/777 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 6 Loss: 0.9267736367479217\n"
     ]
    }
   ],
   "source": [
    "ls = []\n",
    "for epoch in range(7):\n",
    "    model.train()\n",
    "    pred_list = []\n",
    "    label_list = []\n",
    "    for seq, sparse_feats, dense_feats, label in tqdm(train_loader):\n",
    "        seq = seq.reshape( ( -1,3,8,8 ) ).to(device).to(torch.float32)\n",
    "        sparse_feats = sparse_feats.long().to(device)\n",
    "        dense_feats = dense_feats.long().to(device)\n",
    "        label = label.to(device).to(torch.float32)\n",
    "        \n",
    "        pred = model(seq, sparse_feats, dense_feats)\n",
    "        loss = criterion(pred.squeeze(), label)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        model.zero_grad()\n",
    "        \n",
    "        pred_list.extend(pred.squeeze().cpu().detach().numpy())\n",
    "        label_list.extend(label.squeeze().cpu().detach().numpy())\n",
    "        del sparse_feats\n",
    "        del dense_feats\n",
    "        del pred \n",
    "        del seq\n",
    "        del label\n",
    "    \n",
    "    total_loss = cal_acc(label_list,pred_list)\n",
    "    model.eval()\n",
    "\n",
    "    print(\n",
    "        f'Epoch: {epoch} Loss: {total_loss}'\n",
    "    )\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def testf(model, test_loader, device):\n",
    "    model.eval()\n",
    "\n",
    "    pred_list = []\n",
    "    label_list = []\n",
    "\n",
    "    for seq, sparse_feats, dense_feats, label in tqdm(test_loader):\n",
    "        seq = seq.reshape( ( -1,3,8,8 ) ).to(device).to(torch.float32)\n",
    "        sparse_feats = sparse_feats.long().to(device)\n",
    "        dense_feats = dense_feats.long().to(device)\n",
    "        label = torch.tensor(label).to(torch.float32).to(device)\n",
    "\n",
    "        pred = model(seq, sparse_feats, dense_feats)\n",
    "\n",
    "        pred_list.extend(pred.squeeze().cpu().detach().numpy())\n",
    "        label_list.extend(label.squeeze().cpu().detach().numpy())\n",
    "\n",
    "    return pred_list , label_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bd61dfddb86145a5884e837e0a8a3730",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/9 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-31-522a3103a7db>:11: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  label = torch.tensor(label).to(torch.float32).to(device)\n"
     ]
    }
   ],
   "source": [
    "pred , label = testf( model, test_loader , device )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "test[ 'pred' ] = pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "test[['user_id','pred']].to_csv('res/binary_seven.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
