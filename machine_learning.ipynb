{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "714ea00c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3b586cd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def score(res, label, pre):\n",
    "    \"\"\"\n",
    "    This function merges the predicted and actual labels into a dataframe and calculates the score based on this dataframe.\n",
    "    \n",
    "    res: A dataframe containing both predicted and actual labels.\n",
    "    label: The column name for the actual label in the dataframe.\n",
    "    pre: The column name for the predicted label in the dataframe.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Add a new column 'diff' to the dataframe 'res'. The 'diff' is the absolute difference between the predicted and actual labels divided by 7.\n",
    "    res['diff'] = abs((res[pre] - res[label]) / 7)\n",
    "    \n",
    "    # Calculate the score as 1 minus the sum of 'diff' divided by the number of entries in the dataframe. The score is returned.\n",
    "    s = 1 - sum(res['diff']) / len(res)\n",
    "    return s\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bd2bf479",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_label(row):\n",
    "    \"\"\"\n",
    "    Based on the user's ID and the specific date required, calculate the user's 7-day retention score for the current date.\n",
    "    row: A row in df_\n",
    "    \"\"\"\n",
    "    \n",
    "    # Extract the elements from the row\n",
    "    max_date = row['date_max'] # Latest date of login record\n",
    "    min_date = row['date_min'] # Earliest date of login record\n",
    "    label_date = row['date'] # The date that needs to be labeled. We need at least 7 days of login data after this date.\n",
    "    date_list = row['date_list'] # Specific list of login dates\n",
    "    \n",
    "    # Set different conditions to calculate the label\n",
    "    \n",
    "    # The most common condition\n",
    "    # The gap between the last login date (max_date) and label_date is more than 7 days\n",
    "    # For example, the last login date is 130, and label_date is 120\n",
    "    # This indicates that we have login records for the 7 days after label_date in the data, so we can calculate the 7-day retention score for label_date\n",
    "    # Then count the number of login dates that appear within 7 days after date\n",
    "    if label_date + 7 <= max_date:\n",
    "        return sum([1 for x in set(date_list) if label_date < x < label_date+8])\n",
    "    \n",
    "    # If the gap between the last recorded login date (max_date) and label_date is less than 7 days\n",
    "    # For example, the last login date is 125, and label_date is 120\n",
    "    # This means that the current data does not have login records for the 7 days after label_date, so we can't calculate the 7-day retention score for label_date\n",
    "    else:\n",
    "        # Start to judge, is label_date after 153? If so, it might be due to missing records rather than no login\n",
    "        if label_date > 153:\n",
    "            # Further verify the user ID: Is this user in the test set? If not, mark it as -999 and wait for subsequent removal\n",
    "            if row['user_id'] not in user_enddate:\n",
    "                return -999\n",
    "            # If the user ID is indeed in the test set, then make further judgement\n",
    "            else:\n",
    "                # If the date to be predicted for this user ID is less than 7 days from the label_date we are currently labeling\n",
    "                # For example, the date to be predicted for the user ID is 165, and label_date is 160, 165<160+7\n",
    "                # The interval covered by label_date is now in the future of the date to be predicted for the user ID\n",
    "                # Since we can't use the future to predict the past, we need to remove such label_date\n",
    "                # So directly mark as -999 and wait for deletion\n",
    "                if user_enddate[row['user_id']] < label_date+7:\n",
    "                    return -999\n",
    "                # If there is no issue of predicting the past with the future, then regardless of whether there are complete records for the next 7 days, calculate the 7-day retention score based on the existing records\n",
    "                else:\n",
    "                    return sum([1 for x in set(date_list) if label_date < x < label_date+8])\n",
    "        # If label_date is before 130, it is considered that there is no record and it is far from the future to be predicted, so it can be directly marked as -999 and wait for deletion\n",
    "        elif label_date < 130\n",
    "            return -999\n",
    "        # If it is not outside the [130,154] interval, then calculate the 7-day retention score directly based on the existing records\n",
    "        else:\n",
    "            return sum([1 for x in set(date_list) if label_date < x < label_date+8])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8c9d43ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "interval = [x for x in range(131,154)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0643675a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extend_list(row):\n",
    "    \"\"\"\n",
    "    Modify each row of data (the login record list for each user), find the intersection between the maximum interval where the user can calculate the retention score and [131,154].\n",
    "    Before running this function, you must first set the variable user_enddate.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Extract the earliest and latest login dates for each user\n",
    "    date_min = row['date_min']\n",
    "    date_max = row['date_max']\n",
    "    \n",
    "    # Set the effective label date area\n",
    "    interval = [x for x in range(131,154)]\n",
    "    \n",
    "    # Add the date to be tested for each user ID, all the login records we use must be earlier than 7 days before this test date\n",
    "    end_date = user_enddate[row['user_id']]\n",
    "    \n",
    "    # For each row of data, return the days in the intersection we specified\n",
    "    return list(set([x for x in range(date_min,end_date-6)]+interval))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8d8eb9f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data/app_launch_logs.csv')\n",
    "test_a = pd.read_csv('data/test_A.csv')\n",
    "test = pd.read_csv('data/test_B.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "16c11eec",
   "metadata": {},
   "outputs": [],
   "source": [
    "test.columns = ['user_id','date']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5611a4f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.sort_values(['user_id','date']).reset_index(drop=True)\n",
    "df = df[['user_id','date']].drop_duplicates().reset_index(drop=True)\n",
    "df = df[df['user_id'].isin(test_a['user_id'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "083fdd77",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_group = df.groupby('user_id').agg(list).reset_index()\n",
    "df_group['date_max'] = df_group['date'].apply(lambda x: max(x))\n",
    "df_group['date_min'] = df_group['date'].apply(lambda x: min(x))\n",
    "user_enddate = dict(zip(test_a['user_id'],test_a['end_date']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b04140b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_group['date_all'] = df_group.apply(extend_list, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "dfaca073",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ = df_group.explode('date_all')\n",
    "df_.rename(columns = {'date':'date_list','date_all':'date'},inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "27df8218",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_['label'] = df_.apply(get_label, axis=1)\n",
    "train = df_[df_['label']!=-999]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "36b0defe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construct training and test sets\n",
    "train[['user_id','date','label']].to_csv('data/online_trainb.csv',index=False)\n",
    "test['label'] = -1\n",
    "test[['user_id','date','label']].to_csv('data/online_testb.csv',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fc71e8b",
   "metadata": {},
   "source": [
    "### 1. Duration and number of videos watched features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8285f8a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_pb = pd.read_csv('data/user_playback_data.csv')\n",
    "user_pb['count'] = 1\n",
    "user_pb_group = user_pb[['user_id','date','playtime','count']].groupby(['user_id','date'],as_index=False).agg(sum)\n",
    "user_pb_group = user_pb_group[user_pb_group['user_id'].isin(test['user_id'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3a60c815",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.merge(train, user_pb_group, how='left')\n",
    "train.rename(columns = {'playtime':'playtime_last'+str(0),'count':'video_count_last'+str(0)},inplace=True)\n",
    "\n",
    "test = pd.merge(test, user_pb_group, how='left')\n",
    "test.rename(columns = {'playtime':'playtime_last'+str(0),'count':'video_count_last'+str(0)},inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "948fdc79",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(7):\n",
    "    user_pb_group['date'] = user_pb_group['date'] + 1\n",
    "    train = pd.merge(train, user_pb_group, how='left')\n",
    "    train.rename(columns = {'playtime':'playtime_last'+str(i+1),'count':'video_count_last'+str(i+1)},inplace=True)\n",
    "    \n",
    "    test = pd.merge(test, user_pb_group, how='left')\n",
    "    test.rename(columns = {'playtime':'playtime_last'+str(i+1),'count':'video_count_last'+str(i+1)},inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "77020bd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = train.fillna(0)\n",
    "test = test.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2b8f6ca1",
   "metadata": {},
   "outputs": [],
   "source": [
    "pb_feats = []\n",
    "for i in range(8):\n",
    "    pb_feats.append('playtime_last'+str(i))\n",
    "    pb_feats.append('video_count_last'+str(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a860b849",
   "metadata": {},
   "outputs": [],
   "source": [
    "train[['user_id','date']+pb_feats].to_csv('features/online_train_pb.csv',index=False)\n",
    "test[['user_id','date']+pb_feats].to_csv('features/online_test_pb.csv',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c415f196",
   "metadata": {},
   "source": [
    "### 2. Personal information features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dd9aba4",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_trait = pd.read_csv('data/user_portrait_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2697aa87",
   "metadata": {},
   "outputs": [],
   "source": [
    "def deal_ram_rom(x):\n",
    "    if type(x)==float:\n",
    "        return np.nan\n",
    "    elif len(x)==1:\n",
    "        return int(x[0])\n",
    "    else:\n",
    "        return np.mean([eval(i) for i in x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "daadf8fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in ['device_ram','device_rom']:\n",
    "    user_trait['ls_'+i] = user_trait[i].apply(lambda x: x.split(';') if type(x)==str else np.nan)\n",
    "    user_trait[i+'_new'] = user_trait['ls_'+i].apply(lambda x: deal_ram_rom(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "084f97a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "trait_feats = ['device_type','sex','age','education','occupation_status','device_ram_new','device_rom_new']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "843656d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_trait[['user_id']+trait_feats].to_csv('features/user_trait_feature.csv',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bf56d7c",
   "metadata": {},
   "source": [
    "### 3. Time interval since the last login"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5536d7e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_last_diff(row):\n",
    "    date_list = row['date_list']\n",
    "    date_now = row['date']\n",
    "    \n",
    "    ls = [x for x in date_list if x<=date_now]\n",
    "    \n",
    "    return date_now - max(ls) if len(ls)>0 else np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5cce3d0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_group.rename(columns={'date':'date_list'},inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "907e30a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.merge(test,df_group[['user_id','date_list']],how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "6acf0554",
   "metadata": {},
   "outputs": [],
   "source": [
    "train['diff_near'] = train.apply(get_last_diff, axis=1)\n",
    "test['diff_near'] = test.apply(get_last_diff, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "241f9df8",
   "metadata": {},
   "source": [
    "### 4. Whether logged in on the day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d62791f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_launch(row):\n",
    "    return 1 if row['date'] in row['date_list'] else 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "a789c8c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "train['is_launch'] = train.apply(is_launch, axis=1)\n",
    "test['is_launch'] = test.apply(is_launch, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "959ab52c",
   "metadata": {},
   "source": [
    "### 5. Login type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "450e74ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import stats\n",
    "launch = pd.read_csv('data/app_launch_logs.csv')\n",
    "launch = launch[launch['user_id'].isin(test_a['user_id'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "04945b62",
   "metadata": {},
   "outputs": [],
   "source": [
    "launch_type = launch.groupby(['user_id','date'],as_index=False).agg(list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "7eac0220",
   "metadata": {},
   "outputs": [],
   "source": [
    "launch_type['len'] = launch_type['launch_type'].apply(lambda x: len(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "b1d6ce39",
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_launch_type(row):\n",
    "    length = row['len']\n",
    "    ls = row['launch_type']\n",
    "    \n",
    "    if length==2:\n",
    "        return 2\n",
    "    else:\n",
    "        return ls[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "e366ad10",
   "metadata": {},
   "outputs": [],
   "source": [
    "launch_type['launch_type_new'] = launch_type.apply(encode_launch_type, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "31f4dac5",
   "metadata": {},
   "outputs": [],
   "source": [
    "launch_type['launch_type_new'] = launch_type['launch_type_new']+1\n",
    "launch_type['launch_type_new'] = launch_type['launch_type_new'].fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "32e14690",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.merge(train, launch_type[['user_id','date','launch_type_new']], how='left')\n",
    "test = pd.merge(test, launch_type[['user_id','date','launch_type_new']], how='left')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "490f856e",
   "metadata": {},
   "source": [
    "### 6. Total historical number of logins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "ad7c3f16",
   "metadata": {},
   "outputs": [],
   "source": [
    "def GetLaunchNum(row):\n",
    "    end_date_ = row['date']\n",
    "    date_list = row['date_list']\n",
    "    \n",
    "    return sum([1 for x in date_list if x<= end_date_])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "466e98f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "train['launchNum'] = train.apply(GetLaunchNum, axis=1)\n",
    "test['launchNum'] = test.apply(GetLaunchNum, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "422ca0d1",
   "metadata": {},
   "source": [
    "### 7. Number of logins in the past week"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "f35b80fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def GetNumLastWeek(row):\n",
    "    end_date_ = row['date']\n",
    "    date_list = row['date_list']\n",
    "    \n",
    "    return sum([1 for x in date_list if x<= end_date_ and x > end_date_-7])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "c6409138",
   "metadata": {},
   "outputs": [],
   "source": [
    "train['NumLastWeek'] = train.apply(GetNumLastWeek, axis=1)\n",
    "test['NumLastWeek'] = test.apply(GetNumLastWeek, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f40178ac",
   "metadata": {},
   "source": [
    "### 8. Median label of the previous month and mean label of the previous four weeks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "e3f3cdbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = train.sort_values(['user_id','date']).reset_index(drop=True)\n",
    "train_sta = train[['user_id','date','label']].groupby('user_id',as_index=False).agg(list)\n",
    "train_sta.columns = ['user_id','date_all_list','label_list']\n",
    "train = pd.merge(train,train_sta,how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "0c5730a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = test.sort_values(['user_id','date']).reset_index(drop=True)\n",
    "df_ = df_.sort_values(['user_id','date']).reset_index(drop=True)\n",
    "df_sta = df_[['user_id','date','label']].groupby('user_id',as_index=False).agg(list)\n",
    "df_sta.columns = ['user_id','date_all_list','label_list']\n",
    "test = pd.merge(test,df_sta,how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "2e13df1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_his_label(row):\n",
    "    end_date = row['date']\n",
    "    date_all = row['date_all_list']\n",
    "    ls_label = row['label_list']\n",
    "    \n",
    "    ls_new = [x for x in date_all if x+7<=end_date]\n",
    "    \n",
    "    return ls_label[:len(ls_new)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "8e6988ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "train['label_his_list'] = train.apply(get_his_label, axis=1)\n",
    "train['preds_median_30'] = train['label_his_list'].apply(lambda x: np.median(x[-30:]))\n",
    "train['preds_mean_4'] = train['label_his_list'].apply(lambda x: np.mean([x[i] for i in range(-1*len(x),0) if i==-1 or i==-8 or i==-15 or i==-22]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "fdf8b336",
   "metadata": {},
   "outputs": [],
   "source": [
    "test['label_his_list'] = test.apply(get_his_label, axis=1)\n",
    "test['preds_median_30'] = test['label_his_list'].apply(lambda x: np.median(x[-30:]))\n",
    "test['preds_mean_4'] = test['label_his_list'].apply(lambda x: np.mean([x[i] for i in range(-1*len(x),0) if i==-1 or i==-8 or i==-15 or i==-22]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "8926357a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Get_mean_4_weighted(row):\n",
    "    tmp = row['label_his_list']\n",
    "    \n",
    "    if len(tmp) >= 22:\n",
    "        return tmp[-1] * 0.4 + tmp[-8] * 0.3 + tmp[-15] * 0.2 + tmp[-22] * 0.1\n",
    "    elif len(tmp) >= 15:\n",
    "        return tmp[-1] * 0.4 + tmp[-8] * 0.3 + tmp[-15] * 0.2\n",
    "    elif len(tmp) >= 8:\n",
    "        return tmp[-1] * 0.4 + tmp[-8] * 0.3\n",
    "    elif len(tmp) >= 1:\n",
    "        return tmp[-1] * 0.4\n",
    "    else:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "64cc9ef2",
   "metadata": {},
   "outputs": [],
   "source": [
    "train['preds_mean_4_weighted'] = train.apply(Get_mean_4_weighted,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "84967fde",
   "metadata": {},
   "outputs": [],
   "source": [
    "test['preds_mean_4_weighted'] = test.apply(Get_mean_4_weighted,axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd4f93bf",
   "metadata": {},
   "source": [
    "### 9. Weighted median"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "6ab8b651",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('wquantiles-0.6/')\n",
    "import wquantiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "d38762c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def GetWeightedMedian(row):\n",
    "    tmp = row['label_his_list']\n",
    "    tmp = tmp[-30:]\n",
    "    #weight = np.array([0.25 for x in range(9)] + [0.5 for x in range(7)] + [1 for x in range(7)] + [2 for x in range(7)]  )\n",
    "    weight = np.array([(x+1)/(30) for x in range(30)])\n",
    "    \n",
    "    if len(tmp) >= 30:\n",
    "        return wquantiles.median(np.array(tmp),weight)\n",
    "    else:\n",
    "        tmp = [0 for x in range(30-len(tmp))] + tmp\n",
    "        return wquantiles.median(np.array(tmp),weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "c9fa0abe",
   "metadata": {},
   "outputs": [],
   "source": [
    "train['weighted_median'] = train.apply(GetWeightedMedian, axis=1)\n",
    "test['weighted_median'] = test.apply(GetWeightedMedian, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "b73b6235",
   "metadata": {},
   "outputs": [],
   "source": [
    "launch_feats = ['diff_near','is_launch','launch_type_new','launchNum','NumLastWeek','preds_median_30',\n",
    "                'preds_mean_4','preds_mean_4_weighted','weighted_median']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "ab4fc91a",
   "metadata": {},
   "outputs": [],
   "source": [
    "train[['user_id','date']+launch_feats].to_csv('features/launch_online_train.csv',index=False)\n",
    "test[['user_id','date']+launch_feats].to_csv('features/launch_online_test.csv',index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
